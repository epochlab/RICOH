# RICOH

**Project ID:** X4k11zMj

<p align="center">
  <img src="https://github.com/epochlab/ricoh/blob/main/sample.png">
</p>

--------------------------------------------------------------------

#### Adversarial attack methods.
Abstract: *An adversarial attack perturbs an image in such a way that the machine learning model misclassify as an incorrect input vector.*

### Packages
`pillow` `pytorch`

### Requirements
- Both Linux and Windows are supported. Linux is recommended for performance and compatibility reasons.
- 64-bit Python 3.7.9 installation.

### Acknowledgments
[Explaining and Harnessing Adversarial Examples](https://arxiv.org/pdf/1412.6572.pdf) (2015)<br>
[The Limitations of Deep Learning in Adversarial Settings](https://arxiv.org/pdf/1511.07528.pdf) (2015)<br>
[Learning Deep Features for Discriminative Localization](https://arxiv.org/pdf/1512.04150v1.pdf) (2015)<br>
[Adversarial Diversity and Hard Positive Generation](https://arxiv.org/pdf/1605.01775.pdf) (2016)<br>
[Adversarial machine learning at scale](https://arxiv.org/pdf/1611.01236.pdf) (2017)<br>
[Ensemble Adversarial Training: Attacks and Defenses](https://arxiv.org/abs/1705.07204) (2017)<br>
[Adversarial examples in the physical world](https://arxiv.org/pdf/1607.02533.pdf) (2017)<br>
[Boosting adversarial attacks with momentum](https://arxiv.org/pdf/1710.06081.pdf) (2018)